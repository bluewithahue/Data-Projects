{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Credit Card Fraud Detection Analysis\n", "This notebook demonstrates various machine learning models for detecting credit card fraud, including:\n", "- Logistic Regression\n", "- Random Forest\n", "- XGBoost\n", "- Neural Networks\n", "- Isolation Forest (Anomaly Detection)\n", "- SHAP for Interpretability\n", "- LIME for Local Interpretability\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "from xgboost import XGBClassifier\n", "from sklearn.neural_network import MLPClassifier\n", "from sklearn.ensemble import IsolationForest\n", "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n", "import shap\n", "import lime\n", "import lime.lime_tabular\n", "import matplotlib.pyplot as plt\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Load Dataset and Preprocess"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load the dataset\n", "df = pd.read_csv('creditcard.csv')\n", "\n", "# Separate features and target\n", "X = df.drop(columns=['Class'])\n", "y = df['Class']\n", "\n", "# Split the data into training and testing sets\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n", "\n", "# Standardize the features\n", "scaler = StandardScaler()\n", "X_train_scaled = scaler.fit_transform(X_train)\n", "X_test_scaled = scaler.transform(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Logistic Regression"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Logistic Regression\n", "log_reg = LogisticRegression(random_state=42)\n", "log_reg.fit(X_train_scaled, y_train)\n", "y_pred_log = log_reg.predict(X_test_scaled)\n", "print(\"Logistic Regression Performance:\")\n", "print(confusion_matrix(y_test, y_pred_log))\n", "print(classification_report(y_test, y_pred_log))\n", "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_log))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Random Forest"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Random Forest\n", "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n", "rf.fit(X_train_scaled, y_train)\n", "y_pred_rf = rf.predict(X_test_scaled)\n", "print(\"\\nRandom Forest Performance:\")\n", "print(confusion_matrix(y_test, y_pred_rf))\n", "print(classification_report(y_test, y_pred_rf))\n", "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_rf))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### XGBoost"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# XGBoost\n", "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n", "xgb.fit(X_train_scaled, y_train)\n", "y_pred_xgb = xgb.predict(X_test_scaled)\n", "print(\"\\nXGBoost Performance:\")\n", "print(confusion_matrix(y_test, y_pred_xgb))\n", "print(classification_report(y_test, y_pred_xgb))\n", "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_xgb))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Neural Network (MLP)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Neural Networks (MLP)\n", "mlp = MLPClassifier(random_state=42, max_iter=300)\n", "mlp.fit(X_train_scaled, y_train)\n", "y_pred_mlp = mlp.predict(X_test_scaled)\n", "print(\"\\nNeural Network (MLP) Performance:\")\n", "print(confusion_matrix(y_test, y_pred_mlp))\n", "print(classification_report(y_test, y_pred_mlp))\n", "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_mlp))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Isolation Forest"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Isolation Forest (Anomaly Detection)\n", "iso_forest = IsolationForest(contamination=0.0017, random_state=42)  # 0.17% contamination\n", "iso_forest.fit(X_train_scaled)\n", "y_pred_iso = iso_forest.predict(X_test_scaled)\n", "y_pred_iso = np.where(y_pred_iso == -1, 1, 0)  # Convert -1 to 1 (fraudulent), 1 to 0 (non-fraudulent)\n", "print(\"\\nIsolation Forest Performance (Anomaly Detection):\")\n", "print(confusion_matrix(y_test, y_pred_iso))\n", "print(classification_report(y_test, y_pred_iso))\n", "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_iso))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### SHAP Analysis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# SHAP Analysis for XGBoost\n", "print(\"\\nRunning SHAP Analysis for XGBoost...\")\n", "explainer = shap.TreeExplainer(xgb)\n", "shap_values = explainer.shap_values(X_test_scaled)\n", "\n", "# SHAP summary plot\n", "shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### LIME Explanation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# LIME Explanations\n", "print(\"\\nRunning LIME Explanations...\")\n", "lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train_scaled, feature_names=X.columns, class_names=['Non-Fraud', 'Fraud'], discretize_continuous=True)\n", "lime_exp = lime_explainer.explain_instance(X_test_scaled[0], xgb.predict_proba)\n", "lime_exp.show_in_notebook(show_table=True)"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}